{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from TorchCRF import CRF\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "MAX_SEQUENCE_LENGTH = 25  # Adjust as needed\n",
    "EMBEDDING_DIM = 100\n",
    "VOCAB_SIZE = 8000\n",
    "HIDDEN_DIM = 64\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "\n",
    "# Labels and mapping\n",
    "LABELS = ['O', 'B-Task', 'I-Task', 'B-Date', 'I-Date', 'B-Time', 'I-Time']\n",
    "NUM_CLASSES = len(LABELS)\n",
    "label2idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>check tickets for the gathering on may 14th at...</td>\n",
       "      <td>B-Task,I-Task,I-Task,O,B-Task,O,B-Date,I-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confirm a architect to inspect the book by tom...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,I-Task,I-Task,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finish reading chapter 60 of tech conference b...</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,I-Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remember to confirm with Gal about the trainin...</td>\n",
       "      <td>O,O,B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>call a garden follow-up by the 18th in 14</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,O,B-Date,I-Date,O,B-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>check Lia about the client presentation by nex...</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,O,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test preliminary idea report by 3:15 a.m. on W...</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,O,B-Time,I-Time,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>analyze the book tomorrow</td>\n",
       "      <td>B-Task,O,B-Task,B-Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prepare the gym bag table to Daniel by next Tu...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,I-Task,I-Task,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prepare the project report by 4AM on Wednesday</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,O,B-Time,O,B-Date</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Task  \\\n",
       "0  check tickets for the gathering on may 14th at...   \n",
       "1  confirm a architect to inspect the book by tom...   \n",
       "2  finish reading chapter 60 of tech conference b...   \n",
       "3  Remember to confirm with Gal about the trainin...   \n",
       "4          call a garden follow-up by the 18th in 14   \n",
       "5  check Lia about the client presentation by nex...   \n",
       "6  test preliminary idea report by 3:15 a.m. on W...   \n",
       "7                          analyze the book tomorrow   \n",
       "8  prepare the gym bag table to Daniel by next Tu...   \n",
       "9     prepare the project report by 4AM on Wednesday   \n",
       "\n",
       "                                               Label  \n",
       "0  B-Task,I-Task,I-Task,O,B-Task,O,B-Date,I-Date,...  \n",
       "1  B-Task,O,B-Task,I-Task,I-Task,I-Task,I-Task,O,...  \n",
       "2  B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,I-Ta...  \n",
       "3  O,O,B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,...  \n",
       "4    B-Task,O,B-Task,I-Task,O,B-Date,I-Date,O,B-Time  \n",
       "5  B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,O,B-...  \n",
       "6  B-Task,I-Task,I-Task,I-Task,O,B-Time,I-Time,O,...  \n",
       "7                             B-Task,O,B-Task,B-Date  \n",
       "8  B-Task,O,B-Task,I-Task,I-Task,I-Task,I-Task,O,...  \n",
       "9           B-Task,O,B-Task,I-Task,O,B-Time,O,B-Date  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NER_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    check tickets for the gathering on may 14th at...\n",
      "1    confirm a architect to inspect the book by tom...\n",
      "2    finish reading chapter 60 of tech conference b...\n",
      "Name: Task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example training data\n",
    "task_examples = df['Task'].astype(str)\n",
    "print(task_examples[:3])\n",
    "\n",
    "y_train = df['Label'].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "# Vocabulary\n",
    "vocab = defaultdict(lambda: 1)  # Unknown words map to index 1\n",
    "vocab.update({word.strip().lower(): idx+2 for idx, word in enumerate(set(\" \".join(task_examples).split()))})  # Start from index 2\n",
    "\n",
    "# Process data\n",
    "X_train = [[vocab[word] for word in example.split()] for example in task_examples]\n",
    "X_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in X_train]  # Pad to max length\n",
    "y_train_indices = [[label2idx.get(label, 0) for label in sent] for sent in y_train]\n",
    "y_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in y_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded, X_test, y_train_padded, y_test = train_test_split(X_train_padded, y_train_padded, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save vocabulary as regular dictionary\n",
    "with open('NERVocabulary.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(vocab), f)\n",
    "\n",
    "# Save label mappings\n",
    "with open('label_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump({'label2idx': label2idx, 'idx2label': idx2label}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TaskDataset(X_train_padded, y_train_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # BiLSTM doubles hidden size\n",
    "        self.crf = CRF(num_classes)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        emissions = self.fc(x)\n",
    "\n",
    "        if tags is not None:  # Training\n",
    "            loss = -self.crf(emissions, tags, mask=mask)\n",
    "            return loss\n",
    "        else:  # Prediction\n",
    "            return self.crf.viterbi_decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = BiLSTM_NER(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Avg Loss: 2.0703\n",
      "Epoch 2/4, Avg Loss: 0.0285\n",
      "Epoch 3/4, Avg Loss: 0.0085\n",
      "Epoch 4/4, Avg Loss: 0.0041\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            mask = (X_batch != 0)  # Mask for padded tokens - True where not padded\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(X_batch, y_batch, mask)  # CRF loss\n",
    "            # Ensure loss is a scalar\n",
    "            if loss.dim() > 0:  # If loss is a tensor (one per sequence)\n",
    "                loss = loss.mean()  # Reduce to scalar by averaging over batch\n",
    "            loss.backward()  # Backpropagate\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "train_model(model, dataloader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    tokens = [vocab[word.strip().lower()] for word in sentence.split()]\n",
    "    padded = tokens + [0] * (MAX_SEQUENCE_LENGTH - len(tokens))\n",
    "    input_tensor = torch.tensor([padded], dtype=torch.long)\n",
    "    mask = (input_tensor != 0)\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_tensor, mask=mask)[0]  # CRF decode returns list\n",
    "    return [idx2label[idx] for idx in preds[:len(tokens)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: practice presentation slides for the client pitch on June 15th at two pm\n",
      "Predicted: ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time']\n",
      "\n",
      "Sentence: on Oct 22nd at 17 Review the project timeline document\n",
      "Predicted: ['O', 'B-Date', 'I-Date', 'O', 'B-Time', 'B-Task', 'O', 'B-Task', 'I-Task', 'I-Task']\n",
      "\n",
      "Sentence: Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\n",
      "Predicted: ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'O', 'O', 'O', 'O', 'O', 'B-Date', 'O', 'B-Time']\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "test_sentences = [\n",
    "    \"practice presentation slides for the client pitch on June 15th at two pm\",\n",
    "    \"on Oct 22nd at 17 Review the project timeline document\",\n",
    "    \"Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\"\n",
    "]\n",
    "for sentence in test_sentences:\n",
    "    pred = predict(sentence)\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0209,  0.1925, -0.2715,  0.1916, -0.3821,  0.1330, -0.2418],\n",
      "        [-0.0467, -0.2933,  0.2943,  0.0059, -0.0413, -0.1463, -0.1064],\n",
      "        [ 0.1743, -0.3135,  0.2408, -0.0878, -0.1855, -0.2330,  0.0017],\n",
      "        [-0.0941, -0.0898, -0.1595, -0.2542,  0.1967, -0.0070, -0.1066],\n",
      "        [ 0.2417,  0.0167, -0.1076, -0.1131,  0.0923, -0.1108, -0.0908],\n",
      "        [-0.1717,  0.0189, -0.1386, -0.2212, -0.2889, -0.2752,  0.2809],\n",
      "        [ 0.0074, -0.0427, -0.0256,  0.0757, -0.1718,  0.0136, -0.0348]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Check CRF transition matrix\n",
    "print(model.crf.trans_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'NERModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Date       1.00      1.00      1.00      3000\n",
      "        Task       1.00      1.00      1.00      5305\n",
      "        Time       1.00      1.00      1.00      2303\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10608\n",
      "   macro avg       1.00      1.00      1.00     10608\n",
      "weighted avg       1.00      1.00      1.00     10608\n",
      "\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "\n",
    "def evaluate(model, X_data, y_data, idx2label):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y_true in zip(X_data, y_data):\n",
    "            mask = [token != 0 for token in x]\n",
    "            input_tensor = torch.tensor([x], dtype=torch.long)\n",
    "            mask_tensor = torch.tensor([mask], dtype=torch.bool)\n",
    "            preds = model(input_tensor, mask=mask_tensor)[0]  # Viterbi output\n",
    "\n",
    "            true_labels = [idx2label[idx] for idx, m in zip(y_true, mask) if m]\n",
    "            pred_labels = [idx2label[idx] for idx, m in zip(preds, mask) if m]\n",
    "\n",
    "            all_labels.append(true_labels)\n",
    "            all_preds.append(pred_labels)\n",
    "\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(\"F1-score:\", f1_score(all_labels, all_preds))\n",
    "\n",
    "evaluate(model, X_test, y_test, idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Send the updated budget report to Sarah by next Wednesday at 9am\n",
      "Prediction: ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time']\n",
      "True:       ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time']\n",
      "\n",
      "Sentence: Schedule a dentist appointment on the 10th around noon\n",
      "Prediction: ['B-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time']\n",
      "True:       ['B-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time']\n",
      "\n",
      "Sentence: Check inventory levels for the Tel Aviv branch tomorrow noon\n",
      "Prediction: ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'B-Date', 'B-Time']\n",
      "True:       ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'B-Date', 'B-Time']\n",
      "\n",
      "Sentence: Finalize the UI mockups before the meeting on Friday at 14:00\n",
      "Prediction: ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'O', 'O', 'B-Date', 'O', 'B-Time']\n",
      "True:       ['B-Task', 'O', 'B-Task', 'I-Task', 'O', 'O', 'O', 'O', 'B-Date', 'O', 'B-Time']\n",
      "\n",
      "Sentence: Organize carpool for the school event this Sunday at ten\n",
      "Prediction: ['B-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'O', 'B-Time']\n",
      "True:       ['B-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'O', 'B-Time']\n",
      "\n",
      "Sentence: Prepare the slides and notes by April 3rd at 11:30 AM\n",
      "Prediction: ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time']\n",
      "True:       ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time']\n",
      "\n",
      "Sentence: Email the new interns about onboarding next Tuesday\n",
      "Prediction: ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'I-Task', 'B-Date', 'I-Date']\n",
      "True:       ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'I-Task', 'B-Date', 'I-Date']\n",
      "\n",
      "Sentence: Remind John to submit the forms by midnight on the 5th\n",
      "Prediction: ['O', 'B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'O', 'B-Time', 'B-Date', 'I-Date', 'I-Date']\n",
      "True:       ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Time', 'B-Date', 'I-Date', 'I-Date']\n",
      "\n",
      "Sentence: Print handouts for the seminar scheduled at noon on September 1st\n",
      "Prediction: ['I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'O', 'O', 'B-Time', 'O', 'B-Date', 'I-Date']\n",
      "True:       ['B-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'O', 'O', 'B-Time', 'O', 'B-Date', 'I-Date']\n",
      "\n",
      "Sentence: Plan the team lunch in Herzliya after 13:00 this Friday\n",
      "Prediction: ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Time', 'O', 'B-Date']\n",
      "True:       ['B-Task', 'O', 'B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Time', 'O', 'B-Date']\n",
      "\n",
      "Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Date       1.00      1.00      1.00        10\n",
      "        Task       0.84      0.84      0.84        19\n",
      "        Time       1.00      1.00      1.00         9\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        38\n",
      "   macro avg       0.95      0.95      0.95        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    {\n",
    "        \"sentence\": \"Send the updated budget report to Sarah by next Wednesday at 9am\",\n",
    "        \"labels\": \"B-Task,O,B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,I-Date,O,B-Time\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Schedule a dentist appointment on the 10th around noon\",\n",
    "        \"labels\": \"B-Task,O,B-Task,I-Task,O,B-Date,I-Date,O,B-Time\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Check inventory levels for the Tel Aviv branch tomorrow noon\",\n",
    "        \"labels\": \"B-Task,I-Task,I-Task,I-Task,O,B-Task,I-Task,I-Task,B-Date,B-Time\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Finalize the UI mockups before the meeting on Friday at 14:00\",\n",
    "        \"labels\": \"B-Task,O,B-Task,I-Task,O,O,O,O,B-Date,O,B-Time\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Organize carpool for the school event this Sunday at ten\",\n",
    "        \"labels\": \"B-Task,I-Task,I-Task,O,B-Task,I-Task,O,B-Date,O,B-Time\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Prepare the slides and notes by April 3rd at 11:30 AM\",\n",
    "        \"labels\": \"B-Task,O,B-Task,I-Task,I-Task,O,B-Date,I-Date,O,B-Time,I-Time\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Email the new interns about onboarding next Tuesday\",\n",
    "        \"labels\": \"B-Task,O,B-Task,I-Task,I-Task,I-Task,B-Date,I-Date\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Remind John to submit the forms by midnight on the 5th\",\n",
    "        \"labels\": \"B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,O,B-Time,B-Date,I-Date,I-Date\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Print handouts for the seminar scheduled at noon on September 1st\",\n",
    "        \"labels\": \"B-Task,I-Task,I-Task,O,B-Task,O,O,B-Time,O,B-Date,I-Date\"\n",
    "    },\n",
    "    {\n",
    "        \"sentence\": \"Plan the team lunch in Herzliya after 13:00 this Friday\",\n",
    "        \"labels\": \"B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Time,O,B-Date\"\n",
    "    }\n",
    "]\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for sample in test_samples:\n",
    "    sentence = sample[\"sentence\"]\n",
    "    gold = sample[\"labels\"].split(\",\")\n",
    "    pred = predict(sentence)\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"Prediction: {pred}\")\n",
    "    print(f\"True:       {gold}\")\n",
    "    \n",
    "    true_labels.append(gold)\n",
    "    pred_labels.append(pred)\n",
    "\n",
    "print(\"\\nEvaluation Report:\")\n",
    "print(classification_report(true_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
