{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from TorchCRF import CRF\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "MAX_SEQUENCE_LENGTH = 25  # Adjust as needed\n",
    "EMBEDDING_DIM = 100\n",
    "VOCAB_SIZE = 8000\n",
    "HIDDEN_DIM = 128\n",
    "BATCH_SIZE = 15\n",
    "EPOCHS = 10\n",
    "\n",
    "# Labels and mapping\n",
    "LABELS = ['O', 'B-Task', 'I-Task', 'B-Date', 'I-Date', 'B-Time', 'I-Time']\n",
    "NUM_CLASSES = len(LABELS)\n",
    "label2idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finalize Dror on her protest which is on the 1...</td>\n",
       "      <td>B-Task,I-Task,O,O,B-Task,O,O,B-Date,I-Date,I-D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>organize a taxi for the product launch on Wedn...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,O,B-Task,I-Task,O,O,O,B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book the monthly performance review by the dea...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,O,O,O,O,B-Date,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attend lyrics for the wedding on December 26th...</td>\n",
       "      <td>B-Task,I-Task,I-Task,O,B-Task,O,B-Date,I-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test Lia's observance gift before July 21st</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,O,B-Date,I-Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plan tickets for the ritual on Jul 26th at 3:1...</td>\n",
       "      <td>B-Task,I-Task,I-Task,O,B-Task,O,B-Date,I-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Remind me to learn the math quiz report before...</td>\n",
       "      <td>O,O,O,B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I need to study chapter 3 of the biology textb...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,I-Task,O,O,O,O,O,B-Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reserve the keyboard before seven am tomorrow ...</td>\n",
       "      <td>B-Task,I-Task,I-Task,O,B-Time,I-Time,B-Date,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deal with the monthly expense summary by the d...</td>\n",
       "      <td>B-Task,I-Task,O,B-Task,I-Task,I-Task,O,O,O,O,B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Task  \\\n",
       "0  finalize Dror on her protest which is on the 1...   \n",
       "1  organize a taxi for the product launch on Wedn...   \n",
       "2  book the monthly performance review by the dea...   \n",
       "3  attend lyrics for the wedding on December 26th...   \n",
       "4        test Lia's observance gift before July 21st   \n",
       "5  plan tickets for the ritual on Jul 26th at 3:1...   \n",
       "6  Remind me to learn the math quiz report before...   \n",
       "7  I need to study chapter 3 of the biology textb...   \n",
       "8  reserve the keyboard before seven am tomorrow ...   \n",
       "9  deal with the monthly expense summary by the d...   \n",
       "\n",
       "                                               Label  \n",
       "0  B-Task,I-Task,O,O,B-Task,O,O,B-Date,I-Date,I-D...  \n",
       "1  B-Task,O,B-Task,I-Task,O,B-Task,I-Task,O,O,O,B...  \n",
       "2  B-Task,O,B-Task,I-Task,I-Task,O,O,O,O,B-Date,I...  \n",
       "3  B-Task,I-Task,I-Task,O,B-Task,O,B-Date,I-Date,...  \n",
       "4        B-Task,I-Task,I-Task,I-Task,O,B-Date,I-Date  \n",
       "5  B-Task,I-Task,I-Task,O,B-Task,O,B-Date,I-Date,...  \n",
       "6  O,O,O,B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O...  \n",
       "7        O,O,O,B-Task,I-Task,I-Task,O,O,O,O,O,B-Date  \n",
       "8  B-Task,I-Task,I-Task,O,B-Time,I-Time,B-Date,O,O,O  \n",
       "9  B-Task,I-Task,O,B-Task,I-Task,I-Task,O,O,O,O,B...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NER_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    finalize Dror on her protest which is on the 1...\n",
      "1    organize a taxi for the product launch on Wedn...\n",
      "2    book the monthly performance review by the dea...\n",
      "Name: Task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example training data\n",
    "task_examples = df['Task'].astype(str)\n",
    "print(task_examples[:3])\n",
    "\n",
    "y_train = df['Label'].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "# Tokenizer class\n",
    "tokenizer = defaultdict(lambda: 1)  # Unknown words map to index 1\n",
    "tokenizer.update({word: idx+2 for idx, word in enumerate(set(\" \".join(task_examples).split()))})  # Start from index 2\n",
    "\n",
    "# Process data\n",
    "X_train = [[tokenizer[word] for word in example.split()] for example in task_examples]\n",
    "X_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in X_train]  # Pad to max length\n",
    "y_train_indices = [[label2idx.get(label, 0) for label in sent] for sent in y_train]\n",
    "y_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in y_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TaskDataset(X_train_padded, y_train_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # BiLSTM doubles hidden size\n",
    "        self.crf = CRF(num_classes)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        emissions = self.fc(x)\n",
    "\n",
    "        if tags is not None:  # Training\n",
    "            loss = -self.crf(emissions, tags, mask=mask)\n",
    "            return loss\n",
    "        else:  # Prediction\n",
    "            return self.crf.viterbi_decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = BiLSTM_NER(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Avg Loss: 1.5100\n",
      "Epoch 2/10, Avg Loss: 0.0110\n",
      "Epoch 3/10, Avg Loss: 0.0042\n",
      "Epoch 4/10, Avg Loss: 0.0015\n",
      "Epoch 5/10, Avg Loss: 0.0009\n",
      "Epoch 6/10, Avg Loss: 0.0006\n",
      "Epoch 7/10, Avg Loss: 0.0004\n",
      "Epoch 8/10, Avg Loss: 0.0003\n",
      "Epoch 9/10, Avg Loss: 0.0002\n",
      "Epoch 10/10, Avg Loss: 0.0001\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            mask = (X_batch != 0)  # Mask for padded tokens; True where not padded\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(X_batch, y_batch, mask)  # CRF loss\n",
    "            # Ensure loss is a scalar\n",
    "            if loss.dim() > 0:  # If loss is a tensor (e.g., one per sequence)\n",
    "                loss = loss.mean()  # Reduce to scalar by averaging over batch\n",
    "            # print(f\"Loss shape: {loss.shape}, Loss value: {loss.item()}\")  # Debug print\n",
    "            loss.backward()  # Backpropagate\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "train_model(model, dataloader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    tokens = [tokenizer[word] for word in sentence.split()]\n",
    "    padded = tokens + [0] * (MAX_SEQUENCE_LENGTH - len(tokens))\n",
    "    input_tensor = torch.tensor([padded], dtype=torch.long)\n",
    "    mask = (input_tensor != 0)\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_tensor, mask=mask)[0]  # CRF decode returns list\n",
    "    return [idx2label[idx] for idx in preds[:len(tokens)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Practice presentation slides for the client pitch on June 15th at two pm\n",
      "Predicted: ['B-Task', 'B-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time']\n",
      "\n",
      "Sentence: on Oct 22nd at 17 Review the project timeline document\n",
      "Predicted: ['O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time', 'O', 'B-Task', 'I-Task', 'I-Task']\n",
      "\n",
      "Sentence: Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\n",
      "Predicted: ['B-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'O', 'O', 'O', 'B-Date', 'O', 'B-Time']\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "test_sentences = [\n",
    "    \"Practice presentation slides for the client pitch on June 15th at two pm\",\n",
    "    \"on Oct 22nd at 17 Review the project timeline document\",\n",
    "    \"Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\"\n",
    "]\n",
    "for sentence in test_sentences:\n",
    "    pred = predict(sentence)\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0427,  0.0094, -0.0598, -0.0056, -0.1978,  0.1632, -0.1330],\n",
      "        [ 0.0079, -0.0740,  0.1055, -0.0958,  0.0435,  0.0277, -0.0970],\n",
      "        [ 0.0749, -0.0800,  0.0173, -0.0834, -0.1235, -0.1250,  0.0029],\n",
      "        [-0.0703, -0.0239, -0.0121, -0.1166,  0.1440,  0.0007, -0.0216],\n",
      "        [ 0.0070, -0.1092, -0.0860, -0.1130, -0.0519,  0.0119,  0.0534],\n",
      "        [-0.1515, -0.0805, -0.0239, -0.1142, -0.1024, -0.0490,  0.2186],\n",
      "        [-0.0868, -0.0040, -0.0533,  0.1305,  0.0279, -0.0442, -0.0942]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Check CRF transition matrix after training\n",
    "print(model.crf.trans_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
