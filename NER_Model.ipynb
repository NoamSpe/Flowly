{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from TorchCRF import CRF\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "MAX_SEQUENCE_LENGTH = 25  # Adjust as needed\n",
    "EMBEDDING_DIM = 100\n",
    "VOCAB_SIZE = 8000\n",
    "HIDDEN_DIM = 64\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# Labels and mapping\n",
    "LABELS = ['O', 'B-Task', 'I-Task', 'B-Date', 'I-Date', 'B-Time', 'I-Time']\n",
    "NUM_CLASSES = len(LABELS)\n",
    "label2idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I need to check a monitor for the team meeting...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,I-Task,I-Task,O,B-Task,I-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pick up Grandpa's medical prescriptions on jan...</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to learn a dishes for the project timel...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,I-Task,I-Task,O,B-Task,I-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mow the report and mow it by Sunday at twelve am</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't forget to test the protest tickets by to...</td>\n",
       "      <td>O,O,O,B-Task,O,B-Task,I-Task,O,B-Date,O,B-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Remember to watch with Mom about the panel dis...</td>\n",
       "      <td>O,O,B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>book the ruler before 6 am tomorrow and then book</td>\n",
       "      <td>B-Task,I-Task,I-Task,O,B-Time,I-Time,B-Date,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reserve the monthly performance review by the ...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,O,O,O,O,B-Date,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prepare a table at Daniel's for Sunday at 1:50 pm</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O,B-Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>finalize haircut tickets tomorrow at 11:20 AM.</td>\n",
       "      <td>B-Task,I-Task,I-Task,B-Date,O,B-Time,I-Time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Task  \\\n",
       "0  I need to check a monitor for the team meeting...   \n",
       "1  pick up Grandpa's medical prescriptions on jan...   \n",
       "2  I need to learn a dishes for the project timel...   \n",
       "3   mow the report and mow it by Sunday at twelve am   \n",
       "4  Don't forget to test the protest tickets by to...   \n",
       "5  Remember to watch with Mom about the panel dis...   \n",
       "6  book the ruler before 6 am tomorrow and then book   \n",
       "7  reserve the monthly performance review by the ...   \n",
       "8  prepare a table at Daniel's for Sunday at 1:50 pm   \n",
       "9     finalize haircut tickets tomorrow at 11:20 AM.   \n",
       "\n",
       "                                               Label  \n",
       "0  O,O,O,B-Task,I-Task,I-Task,I-Task,O,B-Task,I-T...  \n",
       "1  B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,I-...  \n",
       "2  O,O,O,B-Task,I-Task,I-Task,I-Task,O,B-Task,I-T...  \n",
       "3  B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Date,...  \n",
       "4     O,O,O,B-Task,O,B-Task,I-Task,O,B-Date,O,B-Time  \n",
       "5  O,O,B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,...  \n",
       "6  B-Task,I-Task,I-Task,O,B-Time,I-Time,B-Date,O,O,O  \n",
       "7  B-Task,O,B-Task,I-Task,I-Task,O,O,O,O,B-Date,I...  \n",
       "8  B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O,B-Tim...  \n",
       "9        B-Task,I-Task,I-Task,B-Date,O,B-Time,I-Time  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NER_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I need to check a monitor for the team meeting...\n",
      "1    pick up Grandpa's medical prescriptions on jan...\n",
      "2    I need to learn a dishes for the project timel...\n",
      "Name: Task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example training data\n",
    "task_examples = df['Task'].astype(str)\n",
    "print(task_examples[:3])\n",
    "\n",
    "y_train = df['Label'].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "# Tokenizer class\n",
    "tokenizer = defaultdict(lambda: 1)  # Unknown words map to index 1\n",
    "tokenizer.update({word.strip().lower(): idx+2 for idx, word in enumerate(set(\" \".join(task_examples).split()))})  # Start from index 2\n",
    "\n",
    "# Process data\n",
    "X_train = [[tokenizer[word] for word in example.split()] for example in task_examples]\n",
    "X_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in X_train]  # Pad to max length\n",
    "y_train_indices = [[label2idx.get(label, 0) for label in sent] for sent in y_train]\n",
    "y_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in y_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the tokenizer\n",
    "import pickle\n",
    "\n",
    "# Save tokenizer as regular dictionary\n",
    "with open('NERtokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(tokenizer), f)\n",
    "\n",
    "# Save label mappings\n",
    "with open('label_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump({'label2idx': label2idx, 'idx2label': idx2label}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TaskDataset(X_train_padded, y_train_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # BiLSTM doubles hidden size\n",
    "        self.crf = CRF(num_classes)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        emissions = self.fc(x)\n",
    "\n",
    "        if tags is not None:  # Training\n",
    "            loss = -self.crf(emissions, tags, mask=mask)\n",
    "            return loss\n",
    "        else:  # Prediction\n",
    "            return self.crf.viterbi_decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = BiLSTM_NER(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Avg Loss: 2.0112\n",
      "Epoch 2/10, Avg Loss: 0.0216\n",
      "Epoch 3/10, Avg Loss: 0.0073\n",
      "Epoch 4/10, Avg Loss: 0.0037\n",
      "Epoch 5/10, Avg Loss: 0.0021\n",
      "Epoch 6/10, Avg Loss: 0.0013\n",
      "Epoch 7/10, Avg Loss: 0.0008\n",
      "Epoch 8/10, Avg Loss: 0.0006\n",
      "Epoch 9/10, Avg Loss: 0.0004\n",
      "Epoch 10/10, Avg Loss: 0.0003\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            mask = (X_batch != 0)  # Mask for padded tokens; True where not padded\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(X_batch, y_batch, mask)  # CRF loss\n",
    "            # Ensure loss is a scalar\n",
    "            if loss.dim() > 0:  # If loss is a tensor (e.g., one per sequence)\n",
    "                loss = loss.mean()  # Reduce to scalar by averaging over batch\n",
    "            # print(f\"Loss shape: {loss.shape}, Loss value: {loss.item()}\")  # Debug print\n",
    "            loss.backward()  # Backpropagate\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "train_model(model, dataloader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    tokens = [tokenizer[word.strip().lower()] for word in sentence.split()]\n",
    "    padded = tokens + [0] * (MAX_SEQUENCE_LENGTH - len(tokens))\n",
    "    input_tensor = torch.tensor([padded], dtype=torch.long)\n",
    "    mask = (input_tensor != 0)\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_tensor, mask=mask)[0]  # CRF decode returns list\n",
    "    return [idx2label[idx] for idx in preds[:len(tokens)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: practice presentation slides for the client pitch on June 15th at two pm\n",
      "Predicted: ['O', 'B-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time']\n",
      "\n",
      "Sentence: on Oct 22nd at 17 Review the project timeline document\n",
      "Predicted: ['O', 'B-Date', 'I-Date', 'O', 'B-Time', 'B-Task', 'O', 'B-Task', 'I-Task', 'I-Task']\n",
      "\n",
      "Sentence: Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\n",
      "Predicted: ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'O', 'O', 'O', 'O', 'O', 'B-Date', 'O', 'B-Time']\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "test_sentences = [\n",
    "    \"practice presentation slides for the client pitch on June 15th at two pm\",\n",
    "    \"on Oct 22nd at 17 Review the project timeline document\",\n",
    "    \"Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\"\n",
    "]\n",
    "for sentence in test_sentences:\n",
    "    pred = predict(sentence)\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0182,  0.1741, -0.2277,  0.0909, -0.2753,  0.2018, -0.0731],\n",
      "        [-0.0271, -0.3580,  0.1660,  0.0556, -0.1402, -0.0040, -0.0111],\n",
      "        [ 0.1516, -0.1335,  0.0953, -0.0712, -0.1681, -0.0413,  0.0118],\n",
      "        [-0.0988, -0.1597, -0.1339, -0.1748,  0.2863, -0.1039, -0.0546],\n",
      "        [ 0.2485, -0.0532, -0.1223, -0.2037, -0.0126, -0.1946, -0.0937],\n",
      "        [-0.2029,  0.0778, -0.0674, -0.1996, -0.1476, -0.2037,  0.1267],\n",
      "        [ 0.0148, -0.1261, -0.0482,  0.0389, -0.1065,  0.0317, -0.0370]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Check CRF transition matrix after training\n",
    "print(model.crf.trans_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'NERModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-03\n"
     ]
    }
   ],
   "source": [
    "import dateparser as dp\n",
    "\n",
    "print(dp.parse(\"19:00\", languages=['en'], settings={'DATE_ORDER': 'DMY', 'PREFER_DATES_FROM': 'future'}).date())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
