{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from TorchCRF import CRF\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "MAX_SEQUENCE_LENGTH = 25  # Adjust as needed\n",
    "EMBEDDING_DIM = 100\n",
    "VOCAB_SIZE = 8000\n",
    "HIDDEN_DIM = 64\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# Labels and mapping\n",
    "LABELS = ['O', 'B-Task', 'I-Task', 'B-Date', 'I-Date', 'B-Time', 'I-Time']\n",
    "NUM_CLASSES = len(LABELS)\n",
    "label2idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomorrow i have to test the trousers for the j...</td>\n",
       "      <td>B-Date,O,O,O,B-Task,O,B-Task,I-Task,O,B-Task,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm having a trip with Gal at the cafe tomorro...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,I-Task,O,O,O,B-Date,O,B-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remind me to attend the tech conference report...</td>\n",
       "      <td>O,O,O,B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remind me to clean the board meeting report be...</td>\n",
       "      <td>O,O,O,B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review mail confirmation tomorrow at 9:10</td>\n",
       "      <td>B-Task,I-Task,I-Task,B-Date,O,B-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>read gathering tickets today at 11:15 AM.</td>\n",
       "      <td>B-Task,I-Task,I-Task,B-Date,O,B-Time,I-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>finish reading chapter 38 of physics project b...</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,I-Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>practice the report and practice it by Wednesd...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>study the report and study it by Thursday at t...</td>\n",
       "      <td>B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buy Daniel about the trade show by next week</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,O,B-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Task  \\\n",
       "0  tomorrow i have to test the trousers for the j...   \n",
       "1  I'm having a trip with Gal at the cafe tomorro...   \n",
       "2  Remind me to attend the tech conference report...   \n",
       "3  Remind me to clean the board meeting report be...   \n",
       "4          review mail confirmation tomorrow at 9:10   \n",
       "5          read gathering tickets today at 11:15 AM.   \n",
       "6  finish reading chapter 38 of physics project b...   \n",
       "7  practice the report and practice it by Wednesd...   \n",
       "8  study the report and study it by Thursday at t...   \n",
       "9       buy Daniel about the trade show by next week   \n",
       "\n",
       "                                               Label  \n",
       "0  B-Date,O,O,O,B-Task,O,B-Task,I-Task,O,B-Task,I...  \n",
       "1   O,O,O,B-Task,I-Task,I-Task,O,O,O,B-Date,O,B-Time  \n",
       "2  O,O,O,B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O...  \n",
       "3  O,O,O,B-Task,O,B-Task,I-Task,I-Task,O,B-Date,O...  \n",
       "4               B-Task,I-Task,I-Task,B-Date,O,B-Time  \n",
       "5        B-Task,I-Task,I-Task,B-Date,O,B-Time,I-Time  \n",
       "6  B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,I-Ta...  \n",
       "7  B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Date,...  \n",
       "8  B-Task,O,B-Task,I-Task,I-Task,I-Task,O,B-Date,...  \n",
       "9  B-Task,I-Task,I-Task,I-Task,I-Task,I-Task,O,B-...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NER_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    tomorrow i have to test the trousers for the j...\n",
      "1    I'm having a trip with Gal at the cafe tomorro...\n",
      "2    Remind me to attend the tech conference report...\n",
      "Name: Task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example training data\n",
    "task_examples = df['Task'].astype(str)\n",
    "print(task_examples[:3])\n",
    "\n",
    "y_train = df['Label'].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "# Tokenizer class\n",
    "tokenizer = defaultdict(lambda: 1)  # Unknown words map to index 1\n",
    "tokenizer.update({word.strip().lower(): idx+2 for idx, word in enumerate(set(\" \".join(task_examples).split()))})  # Start from index 2\n",
    "\n",
    "# Process data\n",
    "X_train = [[tokenizer[word] for word in example.split()] for example in task_examples]\n",
    "X_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in X_train]  # Pad to max length\n",
    "y_train_indices = [[label2idx.get(label, 0) for label in sent] for sent in y_train]\n",
    "y_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in y_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the tokenizer\n",
    "import pickle\n",
    "\n",
    "# Save tokenizer as regular dictionary\n",
    "with open('NERtokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(tokenizer), f)\n",
    "\n",
    "# Save label mappings\n",
    "with open('label_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump({'label2idx': label2idx, 'idx2label': idx2label}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TaskDataset(X_train_padded, y_train_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # BiLSTM doubles hidden size\n",
    "        self.crf = CRF(num_classes)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        emissions = self.fc(x)\n",
    "\n",
    "        if tags is not None:  # Training\n",
    "            loss = -self.crf(emissions, tags, mask=mask)\n",
    "            return loss\n",
    "        else:  # Prediction\n",
    "            return self.crf.viterbi_decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = BiLSTM_NER(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Avg Loss: 2.1604\n",
      "Epoch 2/10, Avg Loss: 0.0250\n",
      "Epoch 3/10, Avg Loss: 0.0084\n",
      "Epoch 4/10, Avg Loss: 0.0041\n",
      "Epoch 5/10, Avg Loss: 0.0023\n",
      "Epoch 6/10, Avg Loss: 0.0014\n",
      "Epoch 7/10, Avg Loss: 0.0009\n",
      "Epoch 8/10, Avg Loss: 0.0006\n",
      "Epoch 9/10, Avg Loss: 0.0004\n",
      "Epoch 10/10, Avg Loss: 0.0129\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            mask = (X_batch != 0)  # Mask for padded tokens; True where not padded\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(X_batch, y_batch, mask)  # CRF loss\n",
    "            # Ensure loss is a scalar\n",
    "            if loss.dim() > 0:  # If loss is a tensor (e.g., one per sequence)\n",
    "                loss = loss.mean()  # Reduce to scalar by averaging over batch\n",
    "            # print(f\"Loss shape: {loss.shape}, Loss value: {loss.item()}\")  # Debug print\n",
    "            loss.backward()  # Backpropagate\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "train_model(model, dataloader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    tokens = [tokenizer[word.strip().lower()] for word in sentence.split()]\n",
    "    padded = tokens + [0] * (MAX_SEQUENCE_LENGTH - len(tokens))\n",
    "    input_tensor = torch.tensor([padded], dtype=torch.long)\n",
    "    mask = (input_tensor != 0)\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_tensor, mask=mask)[0]  # CRF decode returns list\n",
    "    return [idx2label[idx] for idx in preds[:len(tokens)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: practice presentation slides for the client pitch on June 15th at two pm\n",
      "Predicted: ['B-Task', 'B-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'I-Task', 'O', 'B-Date', 'I-Date', 'O', 'B-Time', 'I-Time']\n",
      "\n",
      "Sentence: on Oct 22nd at 17 Review the project timeline document\n",
      "Predicted: ['O', 'B-Date', 'I-Date', 'O', 'B-Time', 'B-Task', 'O', 'B-Task', 'I-Task', 'I-Task']\n",
      "\n",
      "Sentence: Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\n",
      "Predicted: ['B-Task', 'I-Task', 'I-Task', 'I-Task', 'O', 'B-Task', 'O', 'O', 'O', 'O', 'O', 'B-Date', 'O', 'B-Time']\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "test_sentences = [\n",
    "    \"practice presentation slides for the client pitch on June 15th at two pm\",\n",
    "    \"on Oct 22nd at 17 Review the project timeline document\",\n",
    "    \"Book a rideshare for the airport which is on Thursday by tomorrow at 20:00\"\n",
    "]\n",
    "for sentence in test_sentences:\n",
    "    pred = predict(sentence)\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1063,  0.3283, -0.2020,  0.1096, -0.3213,  0.2531, -0.2274],\n",
      "        [-0.1284, -0.3469,  0.1402,  0.0268, -0.1159, -0.1149, -0.0678],\n",
      "        [ 0.1827, -0.2965,  0.2179, -0.1539, -0.0948, -0.1242, -0.1741],\n",
      "        [-0.2225, -0.1072, -0.1741, -0.2618,  0.2292, -0.0291, -0.0937],\n",
      "        [ 0.0403, -0.0100, -0.0387, -0.1076,  0.1940, -0.1788,  0.0413],\n",
      "        [-0.1476, -0.0253, -0.2179, -0.2165, -0.0752, -0.1672,  0.2402],\n",
      "        [-0.0240,  0.0292, -0.1216,  0.1739, -0.0231, -0.0071, -0.2256]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Check CRF transition matrix after training\n",
    "print(model.crf.trans_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'NERModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-13\n"
     ]
    }
   ],
   "source": [
    "import dateparser as dp\n",
    "\n",
    "print(dp.parse(\"sunday\", languages=['en'], settings={'DATE_ORDER': 'DMY', 'PREFER_DATES_FROM': 'future'}).date())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
