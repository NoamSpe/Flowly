{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "#from torchcrf import CRF\n",
    "\n",
    "# Define parameters\n",
    "MAX_SEQUENCE_LENGTH = 40  # Adjust as needed\n",
    "EMBEDDING_DIM = 100\n",
    "VOCAB_SIZE = 20000\n",
    "HIDDEN_DIM = 32\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 3\n",
    "\n",
    "# Labels and mapping\n",
    "LABELS = ['O', 'B-Task', 'I-Task', 'B-Date', 'I-Date', 'B-Time', 'I-Time']\n",
    "NUM_CLASSES = len(LABELS)\n",
    "label2idx = {label: idx for idx, label in enumerate(LABELS)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I need to prepare an update mail to the team a...</td>\n",
       "      <td>O,O,O,B-Task,O,I-Task,I-Task,I-Task,O,I-Task,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have a math quiz scheduled for Sunday next w...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,O,O,B-Date,I-Date,I-Date,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to reserve a watch for the product laun...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,I-Task,I-Task,O,I-Task,I-T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manage a new tooth brush by tomorrow at noon</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submit the monthly performance review by the d...</td>\n",
       "      <td>B-Task,O,I-Task,I-Task,I-Task,O,O,O,O,B-Date,I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>make sure to sort out the webinar certificatio...</td>\n",
       "      <td>O,O,O,B-Task,I-Task,O,I-Task,I-Task,O,B-Date,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>watch a new gym bag by tomorrow at noon</td>\n",
       "      <td>B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>call lyrics for the ritual on Jan 2nd at 21:30</td>\n",
       "      <td>B-Task,I-Task,I-Task,O,I-Task,O,B-Date,I-Date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Don't forget to finalize the birthday tickets ...</td>\n",
       "      <td>O,O,O,B-Task,O,I-Task,I-Task,O,B-Date,O,B-Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I need to confirm an update mail to the team a...</td>\n",
       "      <td>O,O,O,B-Task,O,I-Task,I-Task,I-Task,O,I-Task,O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Task  \\\n",
       "0  I need to prepare an update mail to the team a...   \n",
       "1  I have a math quiz scheduled for Sunday next w...   \n",
       "2  I need to reserve a watch for the product laun...   \n",
       "3       manage a new tooth brush by tomorrow at noon   \n",
       "4  submit the monthly performance review by the d...   \n",
       "5  make sure to sort out the webinar certificatio...   \n",
       "6            watch a new gym bag by tomorrow at noon   \n",
       "7     call lyrics for the ritual on Jan 2nd at 21:30   \n",
       "8  Don't forget to finalize the birthday tickets ...   \n",
       "9  I need to confirm an update mail to the team a...   \n",
       "\n",
       "                                               Label  \n",
       "0  O,O,O,B-Task,O,I-Task,I-Task,I-Task,O,I-Task,O...  \n",
       "1  O,O,O,B-Task,I-Task,O,O,B-Date,I-Date,I-Date,O...  \n",
       "2  O,O,O,B-Task,I-Task,I-Task,I-Task,O,I-Task,I-T...  \n",
       "3  B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,O,...  \n",
       "4  B-Task,O,I-Task,I-Task,I-Task,O,O,O,O,B-Date,I...  \n",
       "5  O,O,O,B-Task,I-Task,O,I-Task,I-Task,O,B-Date,O...  \n",
       "6  B-Task,I-Task,I-Task,I-Task,I-Task,O,B-Date,O,...  \n",
       "7  B-Task,I-Task,I-Task,O,I-Task,O,B-Date,I-Date,...  \n",
       "8     O,O,O,B-Task,O,I-Task,I-Task,O,B-Date,O,B-Time  \n",
       "9  O,O,O,B-Task,O,I-Task,I-Task,I-Task,O,I-Task,O...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NER_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I need to prepare an update mail to the team a...\n",
      "1    I have a math quiz scheduled for Sunday next w...\n",
      "2    I need to reserve a watch for the product laun...\n",
      "Name: Task, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Example training data\n",
    "task_examples = df['Task'].astype(str)\n",
    "print(task_examples[:3])\n",
    "\n",
    "y_train = df['Label'].apply(lambda x: x.split(\",\"))\n",
    "\n",
    "# Tokenizer class\n",
    "tokenizer = defaultdict(lambda: 1)  # Unknown words map to index 1\n",
    "tokenizer.update({word: idx+2 for idx, word in enumerate(set(\" \".join(task_examples).split()))})  # Start from index 2\n",
    "\n",
    "# Process data\n",
    "X_train = [[tokenizer[word] for word in example.split()] for example in task_examples]\n",
    "X_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in X_train]  # Pad to max length\n",
    "y_train_indices = [[label2idx.get(label, 0) for label in sent] for sent in y_train]\n",
    "y_train_padded = [seq + [0] * (MAX_SEQUENCE_LENGTH - len(seq)) for seq in y_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = TaskDataset(X_train_padded, y_train_padded)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # BiLSTM doubles hidden size\n",
    "        # self.crf = CRF(num_classes, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        emissions = self.fc(x)\n",
    "        return emissions\n",
    "\n",
    "    def loss(self, emissions, tags, mask):\n",
    "        return -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "\n",
    "    def predict(self, emissions, mask):\n",
    "        return self.crf.decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = BiLSTM_NER(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.5955\n",
      "Epoch 2/3, Loss: 0.0390\n",
      "Epoch 3/3, Loss: 0.0116\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            emissions = model(X_batch)\n",
    "            loss = criterion(emissions.view(-1, NUM_CLASSES), y_batch.view(-1))  # Flatten for loss computation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "train_model(model, dataloader, optimizer, criterion, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    tokens = [tokenizer[word] for word in sentence.split()]\n",
    "    padded = tokens + [0] * (MAX_SEQUENCE_LENGTH - len(tokens))\n",
    "    input_tensor = torch.tensor([padded], dtype=torch.long)\n",
    "    mask = (input_tensor != 0).bool()  # Ensure proper mask format\n",
    "    with torch.no_grad():\n",
    "        emissions = model(input_tensor)\n",
    "        predictions = torch.argmax(emissions, dim=-1).squeeze(0)  # Get highest probability index\n",
    "    return [idx2label[idx.item()] for idx in predictions[:len(tokens)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Time', 'B-Time', 'I-Time', 'B-Date', 'I-Date', 'I-Date', 'B-Task', 'B-Task', 'I-Task']\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"at 10 am tomorrow i need to buy groceries\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
